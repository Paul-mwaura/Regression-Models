# Regression-Models

## **Multilinear, Quantile, Ridge, Lasso and Elastic Net Regressions**

# Specifying Questions
> This repository covers the appilcation of Multilinear, Quantile, Ridge, Lasso and Elastic Net regression on a dataset.

> In this project I have explored the basics of regularization. Regularization can prevent machine learning models from being overfit.

> Regularization is required to help machine learning models generalize when placed in production. Selection of regularization strength involves consideration of the bias-variance trade-off.

> L1 regularization is also known as Lasso regression.

> L2 regularization is also known as Ridge regression.

> L2 and l1 regularization constrain model coefficients to prevent overfitting. L2 regularization constrains model coefficients using a Euclidian norm.

> L2 regularization can drive some coefficients toward zero, usually not to zero. On the other hand, l1 regularization can drive model coefficients to zero.

> Elastic Net regression allows for the implementation of both L1 and L2 regularization techniques.

# Algorithms Used
> Linear Regression

> Quantile Regression

> Ridge Regression

> Lasso Regression

> Elastic Net Regression

# SetUp and Installations
Google Colaboratory/Jupyter Notebooks Python Libraries 

> Pandas 

> Numpy 

> Matplotlib 

> Seaborn 

> Sklearn

# Known Bugs
None

# Technologies Used
Python
